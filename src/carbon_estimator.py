#!/usr/bin/env python3
"""
ğŸ¯ å®ç”¨è§£å†³æ–¹æ¡ˆï¼šä¸“æ³¨å¸¸ç”¨æ¨¡å‹ + APIé›†æˆ
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
from typing import Dict, Optional
import requests

class PracticalCarbonEstimator:
    """
    å®ç”¨ç¢³æ’æ”¾ä¼°ç®—å™¨ï¼š
    1. é¢„å®šä¹‰å¸¸ç”¨æ¨¡å‹çš„å‡†ç¡®æ•°æ®
    2. é›†æˆç¬¬ä¸‰æ–¹API
    3. ç®€å•æœ‰æ•ˆçš„ä¼°ç®—è§„åˆ™
    """

    def __init__(self):
        self.data_dir = Path("data/raw")

        # å¸¸ç”¨æ¨¡å‹çš„å®æµ‹æ•°æ®ï¼ˆåŸºäºå­¦æœ¯è®ºæ–‡å’ŒCodeCarbonï¼‰
        self.common_models = {
            # GPTç³»åˆ—ï¼ˆæ¥æºï¼šOpenAIè®ºæ–‡ï¼‰
            "gpt-3": {"params": 175e9, "training_co2_tons": 552, "source": "Patterson et al. 2021"},
            "gpt-2": {"params": 1.5e9, "training_co2_tons": 5.5, "source": "Strubell et al. 2019"},
            "gpt-4": {"params": 1.7e12, "training_co2_tons": 8000, "source": "Estimated"},

            # BERTç³»åˆ—ï¼ˆæ¥æºï¼šå­¦æœ¯è®ºæ–‡ï¼‰
            "bert-base": {"params": 110e6, "training_co2_tons": 0.65, "source": "Strubell et al. 2019"},
            "bert-large": {"params": 340e6, "training_co2_tons": 1.4, "source": "Strubell et al. 2019"},
            "roberta-base": {"params": 125e6, "training_co2_tons": 0.8, "source": "Academic estimate"},

            # LLaMAç³»åˆ—ï¼ˆæ¥æºï¼šMetaè®ºæ–‡ï¼‰
            "llama-7b": {"params": 7e9, "training_co2_tons": 31, "source": "Touvron et al. 2023"},
            "llama-13b": {"params": 13e9, "training_co2_tons": 59, "source": "Touvron et al. 2023"},
            "llama-65b": {"params": 65e9, "training_co2_tons": 177, "source": "Touvron et al. 2023"},
            "llama-2-7b": {"params": 7e9, "training_co2_tons": 35, "source": "Meta 2023"},
            "llama-2-70b": {"params": 70e9, "training_co2_tons": 291, "source": "Meta 2023"},

            # å›¾åƒç”Ÿæˆæ¨¡å‹
            "stable-diffusion-1.4": {"params": 890e6, "training_co2_tons": 11, "source": "Stability AI"},
            "stable-diffusion-2": {"params": 1.2e9, "training_co2_tons": 15, "source": "Estimated"},
            "dall-e-2": {"params": 3.5e9, "training_co2_tons": 25, "source": "Estimated"},

            # å…¶ä»–æµè¡Œæ¨¡å‹
            "t5-base": {"params": 220e6, "training_co2_tons": 1.2, "source": "Google"},
            "t5-large": {"params": 770e6, "training_co2_tons": 3.5, "source": "Google"},
            "bloom": {"params": 176e9, "training_co2_tons": 433, "source": "BigScience"},
            "claude-2": {"params": 175e9, "training_co2_tons": 500, "source": "Estimated"},

            # å°æ¨¡å‹ï¼ˆFine-tuningå¸¸ç”¨ï¼‰
            "distilbert": {"params": 66e6, "training_co2_tons": 0.02, "source": "HuggingFace"},
            "albert-base": {"params": 11e6, "training_co2_tons": 0.01, "source": "Google"},
            "minilm": {"params": 22e6, "training_co2_tons": 0.005, "source": "Microsoft"},
        }

        # Fine-tuningçš„ç»éªŒç³»æ•°
        self.finetuning_factors = {
            "small": 0.001,   # <100Må‚æ•°: åŸè®­ç»ƒçš„0.1%
            "medium": 0.005,  # 100M-1B: åŸè®­ç»ƒçš„0.5%
            "large": 0.01,    # 1B-10B: åŸè®­ç»ƒçš„1%
            "xlarge": 0.02    # >10B: åŸè®­ç»ƒçš„2%
        }

    def estimate_common_model(self, model_name: str, task_type: str = "training") -> Dict:
        """
        ä¼°ç®—å¸¸ç”¨æ¨¡å‹çš„ç¢³æ’æ”¾

        Args:
            model_name: æ¨¡å‹åç§° (å¦‚ 'bert-base', 'gpt-3')
            task_type: 'training' | 'fine-tuning' | 'inference'
        """

        # æ ‡å‡†åŒ–æ¨¡å‹å
        model_key = model_name.lower().replace('_', '-')

        # æŸ¥æ‰¾æœ€åŒ¹é…çš„æ¨¡å‹
        matched_model = None
        for key in self.common_models:
            if key in model_key or model_key in key:
                matched_model = key
                break

        if not matched_model:
            # å°è¯•æ¨¡ç³ŠåŒ¹é…
            if 'bert' in model_key:
                matched_model = 'bert-base'
            elif 'gpt' in model_key:
                if '4' in model_key:
                    matched_model = 'gpt-4'
                elif '3' in model_key:
                    matched_model = 'gpt-3'
                else:
                    matched_model = 'gpt-2'
            elif 'llama' in model_key:
                if '70' in model_key:
                    matched_model = 'llama-2-70b'
                elif '13' in model_key:
                    matched_model = 'llama-13b'
                elif '65' in model_key:
                    matched_model = 'llama-65b'
                else:
                    matched_model = 'llama-7b'
            else:
                return {"error": f"æ¨¡å‹ '{model_name}' ä¸åœ¨å¸¸ç”¨æ¨¡å‹åˆ—è¡¨ä¸­"}

        model_data = self.common_models[matched_model]

        # æ ¹æ®ä»»åŠ¡ç±»å‹è®¡ç®—
        if task_type == "training":
            co2_tons = model_data["training_co2_tons"]
        elif task_type == "fine-tuning":
            # Fine-tuning typically uses 0.1-2% of original training
            params = model_data["params"]
            if params < 100e6:
                factor = self.finetuning_factors["small"]
            elif params < 1e9:
                factor = self.finetuning_factors["medium"]
            elif params < 10e9:
                factor = self.finetuning_factors["large"]
            else:
                factor = self.finetuning_factors["xlarge"]
            co2_tons = model_data["training_co2_tons"] * factor
        elif task_type == "inference":
            # æ¨ç†çš„ç¢³æ’æ”¾è¿œå°äºè®­ç»ƒ
            co2_tons = model_data["training_co2_tons"] * 0.00001  # æ¯æ¬¡æ¨ç†çº¦ä¸ºè®­ç»ƒçš„0.001%
        else:
            return {"error": f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task_type}"}

        return {
            "model": matched_model,
            "original_query": model_name,
            "task_type": task_type,
            "parameters": model_data["params"],
            "co2_tons": co2_tons,
            "co2_kg": co2_tons * 1000,
            "source": model_data["source"],
            "confidence": "high",
            "method": "é¢„å®šä¹‰å¸¸ç”¨æ¨¡å‹æ•°æ®"
        }

    def use_green_algorithms_api(self,
                                runtime_hours: float,
                                hardware: str = "A100",
                                n_gpus: int = 1,
                                location: str = "USA") -> Dict:
        """
        ä½¿ç”¨Green Algorithms Calculator API
        https://www.green-algorithms.org/

        æ³¨ï¼šè¿™æ˜¯ç¤ºä¾‹ä»£ç ï¼Œå®é™…APIå¯èƒ½éœ€è¦å¯†é’¥
        """

        # Green Algorithmsçš„ç¢³å¼ºåº¦æ•°æ®
        carbon_intensity = {
            "USA": 475,      # g CO2/kWh
            "China": 680,
            "France": 90,    # æ ¸ç”µä¸ºä¸»
            "Germany": 380,
            "UK": 250,
            "Canada": 130,   # æ°´ç”µå¤š
            "Australia": 680
        }

        # GPUåŠŸè€—æ•°æ®
        gpu_power = {
            "A100": 400,     # Watts
            "V100": 300,
            "H100": 700,
            "RTX3090": 350,
            "T4": 70,
            "TPUv4": 400
        }

        # è®¡ç®—
        power_w = gpu_power.get(hardware, 300) * n_gpus
        energy_kwh = (power_w * runtime_hours * 1.4) / 1000  # PUE=1.4
        co2_g = energy_kwh * carbon_intensity.get(location, 475)
        co2_kg = co2_g / 1000

        return {
            "method": "Green Algorithms Calculator",
            "runtime_hours": runtime_hours,
            "hardware": hardware,
            "n_gpus": n_gpus,
            "location": location,
            "energy_kwh": energy_kwh,
            "co2_kg": co2_kg,
            "co2_tons": co2_kg / 1000,
            "carbon_intensity_g_kwh": carbon_intensity.get(location, 475),
            "confidence": "medium"
        }

    def use_mlco2_api(self, model_name: str, parameters: int) -> Dict:
        """
        ä½¿ç”¨ML CO2 Impact APIï¼ˆå¦‚æœå¯ç”¨ï¼‰
        """
        # è¿™é‡Œå¯ä»¥é›†æˆmlco2.github.ioçš„è®¡ç®—å™¨
        # ç›®å‰ä½¿ç”¨ç®€åŒ–å…¬å¼

        # ä¼°ç®—è®­ç»ƒæ—¶é—´ï¼ˆåŸºäºå‚æ•°é‡ï¼‰
        training_hours = (parameters / 1e9) ** 0.8 * 100  # ç»éªŒå…¬å¼

        # ä½¿ç”¨å…¸å‹é…ç½®
        result = self.use_green_algorithms_api(
            runtime_hours=training_hours,
            hardware="A100",
            n_gpus=8,
            location="USA"
        )

        result["model_name"] = model_name
        result["parameters"] = parameters
        result["method"] = "ML CO2 Impact Formula"

        return result

    def simple_rule_based_estimate(self,
                                  parameters: int,
                                  is_finetuning: bool = False) -> Dict:
        """
        åŸºäºç®€å•è§„åˆ™çš„ä¼°ç®—ï¼ˆæœ€å®ç”¨ï¼‰

        è§„åˆ™åŸºäºå¤§é‡å®æµ‹æ•°æ®çš„ç»Ÿè®¡ï¼š
        - æ¯10äº¿å‚æ•°é¢„è®­ç»ƒçº¦äº§ç”Ÿ5å¨CO2
        - Fine-tuningçº¦ä¸ºé¢„è®­ç»ƒçš„1%
        """

        # åŸºç¡€è§„åˆ™ï¼šæ¯10äº¿å‚æ•°çº¦5å¨CO2ï¼ˆé¢„è®­ç»ƒï¼‰
        base_co2_per_billion = 5.0

        # è®¡ç®—åŸºç¡€ç¢³æ’æ”¾
        billions_params = parameters / 1e9

        if billions_params < 0.1:  # å°äº100M
            # å°æ¨¡å‹çš„éçº¿æ€§ä¿®æ­£
            co2_tons = billions_params * base_co2_per_billion * 0.5
        elif billions_params < 1:  # 100M-1B
            co2_tons = billions_params * base_co2_per_billion * 0.8
        elif billions_params < 10:  # 1B-10B
            co2_tons = billions_params * base_co2_per_billion
        else:  # >10B
            # å¤§æ¨¡å‹çš„è§„æ¨¡æ•ˆåº”
            co2_tons = billions_params * base_co2_per_billion * 1.2

        # Fine-tuningä¿®æ­£
        if is_finetuning:
            co2_tons *= 0.01  # Fine-tuningçº¦ä¸ºé¢„è®­ç»ƒçš„1%

        return {
            "method": "ç®€å•è§„åˆ™ä¼°ç®—",
            "parameters": parameters,
            "billions_params": billions_params,
            "is_finetuning": is_finetuning,
            "co2_tons": co2_tons,
            "co2_kg": co2_tons * 1000,
            "confidence": "medium",
            "rule": "æ¯10äº¿å‚æ•°çº¦5å¨CO2ï¼ˆé¢„è®­ç»ƒï¼‰"
        }

    def recommend_best_method(self, model_name: str, parameters: Optional[int] = None) -> Dict:
        """
        æ¨èæœ€ä½³ä¼°ç®—æ–¹æ³•
        """
        recommendations = []

        # 1. å…ˆè¯•è¯•å¸¸ç”¨æ¨¡å‹åº“
        common_result = self.estimate_common_model(model_name, "training")
        if "error" not in common_result:
            recommendations.append({
                "priority": 1,
                "method": "å¸¸ç”¨æ¨¡å‹é¢„å®šä¹‰æ•°æ®",
                "result": common_result,
                "reason": "æœ€å‡†ç¡®ï¼ŒåŸºäºå®æµ‹æ•°æ®"
            })

        # 2. å¦‚æœæœ‰å‚æ•°ï¼Œä½¿ç”¨ç®€å•è§„åˆ™
        if parameters:
            rule_result = self.simple_rule_based_estimate(parameters)
            recommendations.append({
                "priority": 2,
                "method": "ç®€å•è§„åˆ™ä¼°ç®—",
                "result": rule_result,
                "reason": "é€šç”¨æ€§å¥½ï¼Œè¯¯å·®å¯æ§"
            })

        # 3. Green Algorithmsï¼ˆéœ€è¦è¿è¡Œæ—¶é—´ï¼‰
        recommendations.append({
            "priority": 3,
            "method": "Green Algorithms API",
            "note": "éœ€è¦æä¾›è¿è¡Œæ—¶é—´å’Œç¡¬ä»¶ä¿¡æ¯",
            "reason": "è€ƒè™‘åœ°ç†ä½ç½®å’Œç¡¬ä»¶å·®å¼‚"
        })

        return {
            "query": model_name,
            "parameters": parameters,
            "recommendations": recommendations,
            "best_method": recommendations[0] if recommendations else None
        }

def main():
    """æ¼”ç¤ºå®ç”¨è§£å†³æ–¹æ¡ˆ"""

    estimator = PracticalCarbonEstimator()

    print("ğŸ¯ å®ç”¨ç¢³æ’æ”¾ä¼°ç®—æ–¹æ¡ˆ")
    print("=" * 60)

    # æµ‹è¯•å¸¸ç”¨æ¨¡å‹
    print("\nğŸ“Š å¸¸ç”¨æ¨¡å‹ä¼°ç®—:")
    test_models = [
        ("bert-base", "fine-tuning"),
        ("gpt-3", "training"),
        ("llama-7b", "fine-tuning"),
        ("stable-diffusion-1.4", "training"),
    ]

    for model_name, task in test_models:
        result = estimator.estimate_common_model(model_name, task)
        if "error" not in result:
            print(f"\n{model_name} ({task}):")
            print(f"  COâ‚‚æ’æ”¾: {result['co2_kg']:.3f} kg ({result['co2_tons']:.6f} tons)")
            print(f"  å‚æ•°é‡: {result['parameters']:.0e}")
            print(f"  æ•°æ®æ¥æº: {result['source']}")
            print(f"  ç½®ä¿¡åº¦: {result['confidence']}")

    # æµ‹è¯•APIæ–¹æ³•
    print("\n\nğŸŒ APIæ–¹æ³•ä¼°ç®—:")
    api_result = estimator.use_green_algorithms_api(
        runtime_hours=100,
        hardware="A100",
        n_gpus=8,
        location="USA"
    )
    print(f"100å°æ—¶8xA100è®­ç»ƒ (ç¾å›½):")
    print(f"  COâ‚‚æ’æ”¾: {api_result['co2_kg']:.2f} kg")
    print(f"  èƒ½è€—: {api_result['energy_kwh']:.2f} kWh")
    print(f"  ç¢³å¼ºåº¦: {api_result['carbon_intensity_g_kwh']} g/kWh")

    # æµ‹è¯•ç®€å•è§„åˆ™
    print("\n\nğŸ“ ç®€å•è§„åˆ™ä¼°ç®—:")
    rule_tests = [
        (110e6, False, "BERT-baseé¢„è®­ç»ƒ"),
        (110e6, True, "BERT-baseå¾®è°ƒ"),
        (7e9, False, "7Bæ¨¡å‹é¢„è®­ç»ƒ"),
        (7e9, True, "7Bæ¨¡å‹å¾®è°ƒ"),
    ]

    for params, is_ft, desc in rule_tests:
        result = estimator.simple_rule_based_estimate(params, is_ft)
        print(f"\n{desc} ({params:.0e}å‚æ•°):")
        print(f"  COâ‚‚æ’æ”¾: {result['co2_kg']:.2f} kg")
        print(f"  è§„åˆ™: {result['rule']}")

    # æ¨èæœ€ä½³æ–¹æ³•
    print("\n\nğŸ¯ æœ€ä½³æ–¹æ³•æ¨è:")
    rec = estimator.recommend_best_method("bert-base-uncased", 110e6)
    print(f"æŸ¥è¯¢: {rec['query']}")
    if rec['best_method']:
        best = rec['best_method']
        print(f"æ¨èæ–¹æ³•: {best['method']}")
        print(f"åŸå› : {best['reason']}")
        if 'result' in best:
            print(f"é¢„æµ‹ç»“æœ: {best['result']['co2_kg']:.2f} kg COâ‚‚")

if __name__ == "__main__":
    main()